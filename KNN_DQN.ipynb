{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoW(gt, coor, radius_gt, radius):\n",
    "    ### IoW cross section calculation\n",
    "#     print(\"s-1\")\n",
    "    cross_list_0 = [(gt[0]-radius_gt, 0), (gt[0]+radius_gt, 0)]\n",
    "    cross_list_1 = [(gt[1]-radius_gt, 0), (gt[1]+radius_gt, 0)]\n",
    "#     print(\"s-2\")\n",
    "    cross_list_0.append((coor[0]-radius, 1))\n",
    "    cross_list_0.append((coor[0]+radius, 1))\n",
    "    cross_list_1.append((coor[1]-radius, 1))\n",
    "    cross_list_1.append((coor[1]+radius, 1))\n",
    "#     print(\"s-3\")                 \n",
    "    cross_list_0.sort(key = lambda x : x[0])\n",
    "    cross_list_1.sort(key = lambda x : x[0])\n",
    "#     print(\"s-4\") \n",
    "    if (cross_list_0[0][1] != cross_list_0[1][1] and cross_list_1[0][1] != cross_list_1[1][1]):\n",
    "        return (cross_list_0[2][0] - cross_list_0[1][0]) * (cross_list_1[2][0] - cross_list_1[1][0]) / ((radius*2)**2)\n",
    "    else:\n",
    "        return 0.\n",
    "    \n",
    "    \n",
    "def distance_progress(coor_gt, coor_cur, coor_next):\n",
    "    dis_cur = math.sqrt((coor_gt[0]-coor_cur[0])**2 + (coor_gt[1]-coor_cur[1])**2)\n",
    "    dis_next = math.sqrt((coor_gt[0]-coor_next[0])**2 + (coor_gt[1]-coor_next[1])**2)\n",
    "    return dis_cur - dis_next\n",
    "\n",
    "\n",
    "def right_action(coor_gt, coor_cur, radius_gt, radius):\n",
    "    next_coordinate = coor_cur.copy()\n",
    "    action = 0\n",
    "    next_coordinate[0] -= radius/2.\n",
    "    next_coordinate[1] += radius/2.\n",
    "    area = IoW(coor_gt, next_coordinate, radius_gt, radius*0.7)\n",
    "\n",
    "    next_coordinate = coor_cur.copy()\n",
    "    next_coordinate[0] += radius/2.\n",
    "    next_coordinate[1] -= radius/2.\n",
    "    a = IoW(coor_gt, next_coordinate, radius_gt, radius*0.7)\n",
    "    if area < a:\n",
    "        action = 1\n",
    "        area = a\n",
    "\n",
    "    next_coordinate = coor_cur.copy()\n",
    "    next_coordinate[0] -= radius/2.\n",
    "    next_coordinate[1] -= radius/2.\n",
    "    a = IoW(coor_gt, next_coordinate, radius_gt, radius*0.7)\n",
    "    if area < a:\n",
    "        action = 2\n",
    "        area = a\n",
    "    \n",
    "    next_coordinate = coor_cur.copy()\n",
    "    next_coordinate[0] += radius/2.\n",
    "    next_coordinate[1] += radius/2.\n",
    "    a = IoW(coor_gt, next_coordinate, radius_gt, radius*0.7)\n",
    "    if area < a:\n",
    "        action = 3\n",
    "        area = a\n",
    "\n",
    "    next_coordinate = coor_cur.copy()\n",
    "    next_coordinate = coordinate\n",
    "    a = IoW(coor_gt, next_coordinate, radius_gt, radius*.7)\n",
    "    if area < a:\n",
    "        action = 4\n",
    "        area = a\n",
    "    return action\n",
    "    \n",
    "    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_states, n_actions, n_hidden):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 輸入層 (state) 到隱藏層，隱藏層到輸出層 (action)\n",
    "        self.fc1 = nn.Linear(n_states, n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, 32)\n",
    "        self.fc3 = nn.Linear(32, n_actions)\n",
    "        self.out = nn.Softmax(1)\n",
    "        self.log_x = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x) # ReLU # activation\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = x - torch.max(x)\n",
    "        actions_value = self.out(x)\n",
    "        hidden_out = self.log_x(x)\n",
    "        return actions_value, hidden_out\n",
    "\n",
    "\n",
    "class DQN(object):\n",
    "    def __init__(self, n_states, n_actions, n_hidden, batch_size, lr, gamma, target_replace_iter, memory_capacity):\n",
    "        self.eval_net, self.target_net = Net(n_states, n_actions, n_hidden), Net(n_states, n_actions, n_hidden)\n",
    "\n",
    "        self.memory = np.zeros((memory_capacity, n_states * 2 + 2)) # 每個 memory 中的 experience 大小為 (state + next state + reward + action)\n",
    "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=lr)\n",
    "        self.loss_func = nn.NLLLoss()\n",
    "        self.memory_counter = 0\n",
    "        self.learn_step_counter = 0 # 讓 target network 知道什麼時候要更新\n",
    "\n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "        self.n_hidden = n_hidden\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.target_replace_iter = target_replace_iter\n",
    "        self.memory_capacity = memory_capacity\n",
    "\n",
    "    def choose_action(self, state, epsilon):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(state), 0)\n",
    "\n",
    "        # epsilon-greedy\n",
    "        if (np.random.uniform() < epsilon):\n",
    "            action = np.random.randint(0, self.n_actions)\n",
    "        else: \n",
    "            actions_value, ho = self.eval_net(x) # 以現有 eval net 得出各個 action 的分數\n",
    "#             print(\"act v\", actions_value)\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()[0] # 挑選最高分的 action\n",
    "#             print(\"act ! \", action)\n",
    "#             print(\"Sum \", torch.sum(actions_value, dim = 1))\n",
    "\n",
    "        return action\n",
    "    \n",
    "\n",
    "    def store_transition(self, state, action, reward, next_state):\n",
    "        # 打包 experience\n",
    "        transition = np.hstack((state, [action, reward], next_state))\n",
    "\n",
    "        # 存進 memory；舊 memory 可能會被覆蓋\n",
    "        index = self.memory_counter % self.memory_capacity\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "        \n",
    "    def BP(self, state, next_state, reward, right):\n",
    "        q_eval, ho = self.eval_net(torch.unsqueeze(torch.FloatTensor(state),0))\n",
    "        q_target = torch.LongTensor([right])\n",
    "#         print(\"loss q\", ho)\n",
    "#         print(q_target)\n",
    "        loss = self.loss_func(ho, q_target)\n",
    "#         loss = self.loss_func(torch.unsqueeze(ho, 0), torch.unsqueeze(torch.tensor(right, dtype=torch.long),0))\n",
    "#         print(\"   loss\", loss)\n",
    "#         q_eval = self.eval_net(torch.FloatTensor(state))\n",
    "#         q_next = self.target_net(torch.FloatTensor(next_state)).detach()\n",
    "#         q_target = reward + self.gamma * q_next\n",
    "#         print(\"loss q\", q_eval, q_target)\n",
    "#         loss = self.loss_func(q_eval, q_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        \n",
    "    def learn(self):\n",
    "        # 隨機取樣 batch_size 個 experience\n",
    "        sample_index = np.random.choice(self.memory_capacity, self.batch_size)\n",
    "        b_memory = self.memory[sample_index, :]\n",
    "        b_state = torch.FloatTensor(b_memory[:, :self.n_states])\n",
    "        b_action = torch.LongTensor(b_memory[:, self.n_states:self.n_states+1].astype(int))\n",
    "        b_reward = torch.FloatTensor(b_memory[:, self.n_states+1:self.n_states+2])\n",
    "        b_next_state = torch.FloatTensor(b_memory[:, -self.n_states:])\n",
    "\n",
    "        # 計算現有 eval net 和 target net 得出 Q value 的落差\n",
    "        q_eval, ho = self.eval_net(b_state).gather(1, b_action) # 重新計算這些 experience 當下 eval net 所得出的 Q value\n",
    "        q_next = self.target_net(b_next_state).detach() # detach 才不會訓練到 target net\n",
    "        q_target = b_reward + self.gamma * q_next.max(1)[0].view(self.batch_size, 1) # 計算這些 experience 當下 target net 所得出的 Q value\n",
    "        loss = self.loss_func(ho, q_target)\n",
    "\n",
    "        # Backpropagation\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # 每隔一段時間 (target_replace_iter), 更新 target net，即複製 eval net 到 target net\n",
    "        self.learn_step_counter += 1\n",
    "        if self.learn_step_counter % self.target_replace_iter == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "            \n",
    "\n",
    "color = ['#F5B4B3', '#CA885B', '#DAE358', '#9DE358', '#58E39D', \\\n",
    "        '#58E3E1', '#58A2E3', '#5867E3', '#9D58E3', '#E158E3', '#E358B0', '#E35869']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for floor in range(0,5):\n",
    "#     for building in range(0,3):\n",
    "for floor in range(2,3):\n",
    "    for building in range(0,1):\n",
    "        \n",
    "        ## Count the number of data points in building id & floor id\n",
    "        data_num = 0\n",
    "        with open(\"1478167720_9233432_trainingData.csv\", newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',')\n",
    "            for row in spamreader:\n",
    "                if (row[523] == 'BUILDINGID'):\n",
    "                    continue\n",
    "                elif (int(row[523]) is not building or int(row[522]) is not floor):\n",
    "                    continue\n",
    "                data_num += 1\n",
    "        print(data_num)\n",
    "        ## if there are no data, continue to next floor \n",
    "        if (data_num == 0):\n",
    "            continue\n",
    "            \n",
    "        ## Load data points in\n",
    "        wifi_loc_time = np.zeros(shape = (data_num, 524))\n",
    "        i=-1\n",
    "        with open(\"1478167720_9233432_trainingData.csv\", newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',')\n",
    "            for row in spamreader:\n",
    "                if (row[523] == 'BUILDINGID'):\n",
    "                    continue\n",
    "                elif (int(row[523]) is not building or int(row[522]) is not floor):\n",
    "                    continue\n",
    "                i = i+1\n",
    "                if (i > data_num):\n",
    "                    break\n",
    "                # wifi\n",
    "                wifi_loc_time[i-1][:520] = np.array(row[:520])\n",
    "                # location x, y\n",
    "                wifi_loc_time[i-1][520:522] = np.array(row[520:522])\n",
    "                # userID\n",
    "                wifi_loc_time[i-1][522] = np.array(row[526])\n",
    "                # time stamp\n",
    "                wifi_loc_time[i-1][-1] = np.array(row[-1])\n",
    "        \n",
    "        ## Sort by time stamp\n",
    "        wifi_loc_time = wifi_loc_time[wifi_loc_time[:,-1].argsort()]\n",
    "        \n",
    "        ## Map boundaries\n",
    "        longitude_list = np.array([max(wifi_loc_time[:, 520]), -1\\\n",
    "                                   , min(wifi_loc_time[:, 520])])\n",
    "        latitude_list = np.array([max(wifi_loc_time[:, 521]), -1\\\n",
    "                                   , min(wifi_loc_time[:, 521])])\n",
    "        \n",
    "        ## KNN initial calculation\n",
    "        nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(wifi_loc_time[:,:520])\n",
    "        distances, indices = nbrs.kneighbors(wifi_loc_time[:,:520])\n",
    "\n",
    "        ## DQN's hyper para\n",
    "        n_actions = 5\n",
    "        # state: RSSI (520), coordinate (2), radius (1), history (50)\n",
    "        n_states = 520 + 2 + 1 + 50 \n",
    "        n_hidden = 512\n",
    "        batch_size = 100\n",
    "        gamma = 0.1 # reward discount factor\n",
    "        target_replace_iter = 100\n",
    "        memory_capacity = 200\n",
    "        n_episodes = 10000\n",
    "        lr = 0.0001\n",
    "        eps = 0\n",
    "        max_search_steps = 10\n",
    "        it = 0\n",
    "        cost_it = 0\n",
    "        avg_it = 0\n",
    "        delta = 0.7\n",
    "        log_step = 500\n",
    "        Rewards = 0\n",
    "        radius_gt = 0.5\n",
    "        it_list = []\n",
    "        \n",
    "        dqn = DQN(n_states, n_actions, n_hidden, batch_size, lr, gamma, target_replace_iter, memory_capacity)\n",
    "\n",
    "        ## DQN training\n",
    "        for k in range(n_episodes):\n",
    "            print(\"Epoch - \", k, \"eps : \", eps)\n",
    "            avg_it = 0\n",
    "            for i in range(len(wifi_loc_time)):\n",
    "                # some important variables used for training\n",
    "                Rewards = 0\n",
    "                Goal = False\n",
    "                alpha = 0.7\n",
    "                cost_it = 0\n",
    "                next_coordinate = np.array([0, 0])\n",
    "                next_radius = 0\n",
    "                rect1 = []\n",
    "                \n",
    "                ## 1. KNN locates initial coordinates and radius\n",
    "                Hx = 0.\n",
    "                Hy = 0.\n",
    "                for m in range(3):\n",
    "                    Hx += wifi_loc_time[indices[i, m], 520]\n",
    "                    Hy += wifi_loc_time[indices[i, m], 521]\n",
    "                Hx /= 3.\n",
    "                Hy /= 3.\n",
    "                coordinate = np.array([Hx, Hy])\n",
    "                radius = 10.\n",
    "                # initial history, 5n vector\n",
    "                history = np.zeros(shape=(5*max_search_steps,), dtype=int)\n",
    "                \n",
    "                ## 2. Check initial KNN IoW\n",
    "                while True:\n",
    "                    IoW_cur = IoW(wifi_loc_time[i, 520:522], coordinate, radius_gt, radius)\n",
    "                    if (IoW_cur == 0):\n",
    "                        radius *= 1.5\n",
    "                    elif (IoW_cur > delta):\n",
    "#                         print(\"Precise location!\")\n",
    "                        Goal = True\n",
    "                        break\n",
    "                    else:\n",
    "                        break\n",
    "                if (Goal == True):\n",
    "                    continue\n",
    "                # initial state: RSSI (520), coordinate (2), radius (1), history (50)\n",
    "                state = np.concatenate((wifi_loc_time[i, :520], coordinate.copy(), np.array([radius]), history.copy()), axis=0)\n",
    "                \n",
    "                ## Plot gt region\n",
    "                if k % log_step == 0:\n",
    "                    fig = plt.figure()\n",
    "                    ax = fig.add_subplot(111)\n",
    "                    plt.xlim(longitude_list[0], longitude_list[2])\n",
    "                    plt.ylim(latitude_list[0], latitude_list[2])\n",
    "                    rect0 = plt.Rectangle((wifi_loc_time[i,520]-radius_gt, wifi_loc_time[i,521]-radius_gt), 2*radius_gt, 2*radius_gt, alpha=0.9)\n",
    "                    rect1.append(plt.Rectangle((coordinate[0]-radius, coordinate[1]-radius), 2*radius, 2*radius, alpha = 0.6, color = color[-1]))\n",
    "                \n",
    "                ## 3. Searching starts\n",
    "                for t in range(max_search_steps):\n",
    "                    right = right_action(wifi_loc_time[i, 520:522], coordinate, radius_gt, radius)\n",
    "#                     print(t, \"round, right action is \", right)\n",
    "                    it = 0\n",
    "                    if (radius < 0.5):\n",
    "#                         print(\"Radius is small enough and searching ends\")\n",
    "                        Goal = True\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "                    while True:\n",
    "                        it += 1\n",
    "                        ### (1) select an action\n",
    "                        action = dqn.choose_action(state, eps)\n",
    "#                         print(\"[\", action, \"]\", it)\n",
    "                        ### (1) - 1. New Center\n",
    "                        ### 0 -> \"Up Left\"\n",
    "                        ### 1 -> \"Up Right\"\n",
    "                        ### 2 -> \"Down Left\"\n",
    "                        ### 3 -> \"Down Right\"\n",
    "                        ### 4 -> \"Center\"\n",
    "                        next_coordinate = coordinate.copy()\n",
    "                        if (action == 0):\n",
    "                            next_coordinate[0] -= radius/2.\n",
    "                            next_coordinate[1] += radius/2.\n",
    "                        elif (action == 1):\n",
    "                            next_coordinate[0] += radius/2.\n",
    "                            next_coordinate[1] -= radius/2.\n",
    "                        elif (action == 2):\n",
    "                            next_coordinate[0] -= radius/2.\n",
    "                            next_coordinate[1] -= radius/2.\n",
    "                        elif (action == 3):\n",
    "                            next_coordinate[0] += radius/2.\n",
    "                            next_coordinate[1] += radius/2.\n",
    "                        else:\n",
    "                            next_coordinate = coordinate\n",
    "                        ### (1) - 2. New radius\n",
    "                        next_radius = radius * alpha\n",
    "                        ### (1) - 3. New IoW\n",
    "                        next_IoW = IoW(wifi_loc_time[i, 520:522], next_coordinate, radius_gt, next_radius)\n",
    "#                         print(\"  IoW\", IoW_cur, \"->\", next_IoW)\n",
    "                        if (next_IoW > delta and action == right):\n",
    "#                             print(\"Precise location!\")\n",
    "                            Goal = True\n",
    "                            cost_it += it\n",
    "                            del next_coordinate\n",
    "                            break\n",
    "                        elif (next_IoW > IoW_cur and action == right):\n",
    "                            # close score\n",
    "                            reward = distance_progress(wifi_loc_time[i, 520:522], coordinate, next_coordinate)\n",
    "#                             print(\"  [C]  ontinue next round of searching, reward\", reward, \"\\n   location\", coordinate, \"->\", next_coordinate, \"\\n   radius\", radius,\"->\" , next_radius)\n",
    "                            IoW_cur = next_IoW\n",
    "                            next_history = history.copy()\n",
    "                            one_hot = t*5 + action\n",
    "                            next_history[one_hot] = 1\n",
    "                            next_state = np.concatenate((wifi_loc_time[i,:520], next_coordinate, np.array([next_radius]), next_history), axis=0)\n",
    "                            dqn.store_transition(state.copy(), action, reward, next_state.copy())\n",
    "                            radius = next_radius\n",
    "                            coordinate = next_coordinate\n",
    "                            history = next_history.copy()\n",
    "                            state = next_state.copy()\n",
    "                            Rewards += reward\n",
    "                            del next_history\n",
    "                            del next_state\n",
    "                            del next_coordinate\n",
    "                            cost_it += it\n",
    "                            if k % log_step == 0:\n",
    "                                # Plot\n",
    "                                rect1.append(plt.Rectangle((coordinate[0]-radius, coordinate[1]-radius), 2*radius, 2*radius, alpha = 0.6, color = color[t]))\n",
    "                            break\n",
    "                        else:\n",
    "                            reward = distance_progress(wifi_loc_time[i, 520:522], coordinate, next_coordinate)\n",
    "                            next_history = history.copy()\n",
    "                            one_hot = t*5 + action\n",
    "                            next_history[one_hot] = 1\n",
    "                            next_state = np.concatenate((wifi_loc_time[i,:520], next_coordinate, np.array([next_radius]), next_history), axis=0)\n",
    "                            Rewards += reward\n",
    "                            # back_propagation\n",
    "                            dqn.BP(state, next_state, reward, right)\n",
    "#                             print(\"  [R]  epeat this round, reward\", reward, \"\\n   location\", coordinate, \"->\", next_coordinate, \"\\n   radius\", radius,\"->\" , next_radius)\n",
    "                        if it > 10:\n",
    "                            cost_it += it\n",
    "                            print(\"--------------------------Training fail!---------------------------\")\n",
    "                            break\n",
    "                    \n",
    "                    if (Goal == True):\n",
    "                        print(\"End searching for \", i ,\", costs \", cost_it)\n",
    "                        break\n",
    "                del coordinate\n",
    "                del state\n",
    "                if k % log_step == 0:\n",
    "                    for x in rect1:\n",
    "                        ax.add_patch(x)\n",
    "                    ax.add_patch(rect0)\n",
    "                    plt.title(\"loc: \"+str(i)+\" epoch \"+str(k)+\" cost total searching \"+str(cost_it)+\" times\")\n",
    "                    plt.savefig(\"loc_\"+str(i)+\"_e_\"+str(k))\n",
    "                    plt.close()\n",
    "                    plt.cla()\n",
    "                    plt.clf()\n",
    "                    rect1.clear()\n",
    "#                 if dqn.memory_counter > memory_capacity:\n",
    "#                     dqn.learn()\n",
    "                avg_it += cost_it\n",
    "            clear_output(wait=True)\n",
    "            it_list.append(avg_it/len(wifi_loc_time))\n",
    "            print(\"avg_it : \", avg_it/len(wifi_loc_time))\n",
    "            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
